{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 완전 연결 네트워크나 컨브넷의 특징은 메모리가 없다는 것임. 이런 네트워크로 시퀀스나 시계열 데이터 포인트를 처리하려면 네트워크에 전체 시퀀스를 주입해야 함. 즉 전체 시퀀스를 하나의 데이터 포인트로 변환해야 함. 이런 네트워크를 **피드포워드 네트워크**(feedforward network)라고 부름.\n",
    "+ 이와 반대로 사람의 문장을 읽는 것처럼 이전에 나온 것을 기억하면서 단어별로 또는 한눈에 들어오는 만큼씩 처리할 수 있음. 이 모델은 과거 정보를 사용하며 구축되며 새롭게 얻은 정보를 계속 업데이트 함.\n",
    "+ **순환 신경망**(recurrent neural network, RNN)이 이런 네트워크의 한 사례라고 볼 수 있음.\n",
    "    + 시퀀스의 원소를 순회하면서 지금까지 처리한 정보를 **상태**(state)에 저장함.\n",
    "    + RNN은 내부에 루프(loop)를 가진 신경망의 한 종류임.\n",
    "    + (IMDB의 사례의 경우) RNN의 상태는 2개의 다른 시퀀스를 처리하는 사이에 재설정됨. 하나의 시퀀스가 여전히 하나의 데이터 포인트로 간주됨.\n",
    "    + 네트워크는 시퀀스의 원소를 차례대로 방문함.\n",
    "    \n",
    "*순환 네트워크 루프를 가진 네트워크*\n",
    "\n",
    "<a href=\"https://ibb.co/LdtL67R\"><img src=\"https://i.ibb.co/v4P7mnq/539-DEDE0-306-F-4132-B1-BC-3-A6-ACDF9-C679-png.jpg\" alt=\"539-DEDE0-306-F-4132-B1-BC-3-A6-ACDF9-C679-png\" width=\"300\" height=\"300\" align=left border=\"0\"></a><br /><a target='_blank' href='https://carinsuranceguru.org/is-it-possible-to-buy-a-car-and-insurance-for-a-tourist-in-the-u-s'></a>\n",
    "<br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br />\n",
    "\n",
    "+ 간단한 RNN 구현 사례(바로 아래 코드 참고)\n",
    "    + 자료형식: (timesteprs, input_features)인 2D 텐서로 인코딩된 벡터\n",
    "    + 각 타임스텝 t에서 현재 상태와 ((input_features,) 크기의) 입력을 연결하여 출력을 계산함. 그 다음 이 출력을 다음 스텝의 상태로 설정함.\n",
    "    + 첫 번째 타임 스탭에서는 이전 출력이 정의되지 않으므로 현재 상태가 없음. 이때는 네트워크의 **초기 상태**(initial state)인 0 벡터로 상태를 초기화함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 의사코드로 표현한 RNN\n",
    "\n",
    "state_t = 0 # 타임스텝 t의 상태\n",
    "for input_t in input_sequences: # 시퀀스의 원소를 반복함\n",
    "    output_t = f(input_t, state_t) # 여기서 f 함수는 입력과 상태를 출력으로 변환함.\n",
    "    state_t = output_t # 출력은 다음 반복을 위한 상태가 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 좀 더 자세한 의사코드로 표현한 RNN\n",
    "\n",
    "state_t = 0\n",
    "for input_t in input_sequences: # 시퀀스의 원소를 반복함\n",
    "    output_t = activation(dot(W, input_t) + dot(U, state_t) + b) \n",
    "    state_t = output_t # 출력은 다음 반복을 위한 상태가 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 넘파이로 구현한 간단한 RNN\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "timesteps = 100 # 입력 시퀀스에 있는 타임 스텝 수\n",
    "input_features = 32 # 입력 특성의 차원\n",
    "output_features = 64 # 출력 특성의 차원\n",
    "\n",
    "inputs = np.random.random((timesteps, input_features)) # 입력데이터: 예제를 위해 생성한 난수\n",
    "\n",
    "state_t = np.zeros((output_features, )) # 초기 상태: 모두 0인 데이터\n",
    "\n",
    "# 랜덤한 가중치 생성\n",
    "W = np.random.random((output_features, input_features))\n",
    "U = np.random.random((output_features, output_features))\n",
    "b = np.random.random((output_features, ))\n",
    "\n",
    "successive_outputs = []\n",
    "for input_t in inputs:  # input_t는 크기가 (input_features,)인 벡터\n",
    "    output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b) # 입력과 현재 상태(이전 출력)를 연결하여 현재 출력을 얻음.\n",
    "    \n",
    "    successive_outputs.append(output_t) # 이 출력을 리스트에 저장함.\n",
    "    \n",
    "    sate_t = output_t # 다음 타임스텝을 위해 네트워크의 상태를 업데이트 함.\n",
    "    \n",
    "final_output_sequence = np.stack(successive_outputs, axis = 0) # 최종 출력은 크기가 (timesteps, output_features)인 2D 텐서임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
